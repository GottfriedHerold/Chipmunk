\subsection{Encoding HVC openings}\label{sect:efficientencoding}


\gnote{Make this a section instead of a subsection?}

% \gnote{Explain relationship to Babai's algorithm}

To reduce the size needed to transmit openings in our final HVC construction, we employ a non-trivial encoding scheme.
Let us first sketch the idea and how it relates to lattice enumeration, before defining it more formally in \autoref{fig:EncodingCoeff}.

Our HVC construction is, except for projections and decompositions, a Merkle tree with a homomorphic hash function.
Time slots $t$ correspond to paths in the Merkle tree and our openings contain the labels $\vec{p}_i$ along the path, together with the sibling nodes' labels $\vec{s}_i$.
Usually, when opening a path of a Merkle tree, it is not necessary to actually include most of the nodes $\vec{p}_i$ along the Merkle path in the opening, but only the sibling nodes $\vec{s}_i$ (ignoring possible special handling at the root or leaf).
The reason is that for any valid opening of a usual Merkle tree, we have 
\[
 H(\vec{p}_i,\vec{s}_i) = \vec{p}_{i-1} \quad\text{or}\quad H(\vec{s}_i,\vec{p}_i) = \vec{p}_{i-1}\enspace, 
\]
where $H$ is the hash function used in the construction (concretely for us, Ajtai's hash function $\hashajtai$).
This allows to verifier to compute $\vec{p}_i$ from $\vec{p}_{i-1}$ by itself, if given $\vec{s}_i$.

For us, the corresponding relation (ignoring smallness constraints) instead reads
\[
 H(\vec{p}_i,\vec{s}_i) =  \projmod{q}(\vec{p}_{i-1})  \quad\text{or}\quad H(\vec{s}_i,\vec{p}_i) = \projmod{q}(\vec{p}_{i-1})
\]
throwing $\projmod{q}$, i.e.\ $\projring$ and reduction modulo $q$, in the mix, which complicates things.

Now, for individually verifying openings, the above idea still works out due the size constraints:
the bounds $\norm{\vec{p}_i} \leq \eta$ and $\norm{\projring(\vec{p}_i)}\leq \tfrac{q-1}{2}$ for individually verifying openings imply that $\vec{p}_i$ is actually uniquely determined by $\projmod{q}(\vec{p}_i)$.
Indeed, $\vec{p}_i$ is given by $\vec{p}_i = \decompmod{q}(\projmod{q}(\vec{p}_i))$.

For aggregate openings, this unfortunately no longer holds:
for any given output $h\in\ring_q$ of Ajtai's hash function, the equation $\projmod{q}(\vec{p}_i) = h$ can have many solutions
that satisfy the size constraints that we impose on aggregate openings.

So our task boils down to efficiently encode small elements (in $\norm{.}_{\infty}$-norm) from a lattice coset for the lattice $\latmodular \coloneqq \{\vec{x}\in\ring^\limbs \mid \projring(\vec{x})\bmod q = 0\}$, where $\limbs = \ceil{\log_{2\eta+1}q}$.
We do this, essentially, by performing lattice enumeration and encoding the given solution by the path in the search tree that lattice enumeration would use to find it.
% \gnote{TODO: Ref to remark}

% While our presentation is self-contained and does not require knowledge of lattice enumeration, the following 

\begin{remark}[Lattice enumeration]\label{rmk:RelationshipToBabai}
% In our notation the $B$ in $\latencode$ and $\latdecode$ is for Babai.
Let us now explain how our encoding and decoding is connected to Babai's algorithm~\cite{DBLP:journals/combinatorica/Babai86} (or more precisely, the generalization in~\cite{RSA:LinPei11}) and lattice enumeration.
Note that, to keep our exposition self-contained, both our actual algorithm in \autoref{fig:EncodingCoeff} and its analysis make no mention of this connection and can be understood without it.
The problem we need to solve is, essentially, to enumerate the solutions to $\proj_q(\vec{v}) = h$ by encodings $\overline{\vec{v}}$, where short solutions $\vec{v}$ should be encoded by small $\overline{\vec{v}}$.
The set of all such solutions is a lattice coset for the kernel of $\proj_q$. So this is essentially a close vector problem for a lattice.

Let $\kernelbasis = \{\vec{b}_0,\vec{b}_1\ldots\}$ be a $\ZZ$-basis for the kernel of $\proj_q$ (which could be any linear map here).
Writing everything wrt.\ this basis, we are looking at solutions $\vec{c} = (c_0,c_1\ldots)$ of
\[
\proj_q\Bigl(\sum_{i\geq 0} c_i\vec{b}_i\Bigr) = h\enspace,
\]
where $\sum_{i\geq 0} c_i\vec{b}_i$ is integral.
Note that the $c_i$ themselves do not need to be integers, but are rational numbers.
By construction, if $\vec{c}$ is a solution then so is $\vec{c} + \vec{\delta}$ for any integral $\vec{\delta}$.

Consequently, if any solution exists, we can find a reference solution $\vec{c}'$ where each $c_i\in [-\tfrac12,+\tfrac12[$, which corresponds to what is often called Babai rounding.
A naive way to encode a given $\vec{c}$ is then by encoding it by $\vec{\delta} \coloneqq \vec{c} - \vec{c}'$, which is an integral vector.

A better way, especially if the basis is very non-orthogonal, is to use Babai's nearest plane(s) algorithm~\cite{DBLP:journals/combinatorica/Babai86,RSA:LinPei11}:
we only use the naive construction to obtain the first coefficient $\delta_0$. For fixed $\delta_0$, we can plug this into the equation and consider solutions to
\[
\proj_q\Bigl(\sum_{i\geq 1} c_i\vec{b}_i\Bigr) = h - \proj_q(c'_0 + \delta_0\vec{b}_0)\enspace,
\]
where $\sum_{i\geq 1} c_i\vec{b}_i$ is integral. We then use recursion to solve a problem in dimension 1 less.
Note that the reference solution obtained in a given step during this recursion depends on the choices of $\delta_0,\ldots$ made in previous steps.

Our actual algorithms $\latencode$ and $\latdecode$ correspond precisely to this, with the only difference being that we work over\footnote{Normally, we would have to expand everything over $\ZZ$ and increase dimension $n$-fold, but since both $\proj_q$ and our given $\kernelbasis$ can be written with $\ZZ$ coefficients, all monomials are independent and we can just work in $\ring$.} $\ring$ and that we only perform the above recursive step \emph{once} to get a single coeffient $\delta_q$ before using the naive algorithm to get the rest of the coefficients $(\alpha_1,\alpha_2,\ldots)$ in one go.
The reason we perform the recursive step only once is that $(\vec{b}_1,\vec{b}_2,\ldots)$ is almost orthogonal and parallel to the coordinate axes (the latter condition is relevant, because we work in $\norm{.}_\infty$, not $\norm{.}_2$), so the naive way is ``good enough''.
Only $\vec{b}_0$ needs special handling.
% Enumeration-based lattice algorithms for the closest vector problem enumerate those solutions in a tree-like fashion in what is a generalization of Babai's algorithm.
% So we can encode solutions by the path in the enumeration tree that was taken.
% 
% 
% 
% 
% One way to write Babai's algorithm and its enumeration generalization for full-rank lattices is as follows:
% We pick the solution to $\proj_q(\vec{v}) = h$ by fixing one coordinate (wrt. $\kernelbasis$) of the solutions after another.
% For this, consider the set $S_0$ of all $c_0$ for which $\proj_q(c_0\vec{b}_0 + \sum_{i\geq 1} c_i\vec{b}_i) = h$ has a solution.
% The set $S_0$ has the form $c_0\in\{\alpha_0\cdot v + c_0' \mid \alpha_0\in\ZZ\}$ for some $v\in\ZZ$ and any fixed solution $c_0'\in S_0$.
% Babai's algorithm only considers the particular value of $c_0'$ that greedily minimizes the $\norm{.}_2$ that this choice will ensure (by looking at the contribution in orthogonal projection to the span of $\vec{b}_0$).
% Enumeration algorithms also consider other solutions, parameterized by $\alpha$.
% 
% Once $\alpha_0$ is fixed, we can shift the target by considering $\proj_q(\sum_{i\geq 1} c_i\vec{b}_i) = h - \proj_q(c_0\vec{b}_0)$ and recursing this approach.
% The sequence of $\alpha_i$ then encodes the particular solution.
% 
% Our encoding is an adaption of this approach to $\norm{.}_{\infty}$.
% The difference is that we greedily minimize the $\norm{.}_{\infty}$ norm that a given choice of $c_0'$ will contribute, meaning we minimize $\abs{c_0'}$.
% Then $\alpha_0$ corresponds to $\delta_q$.
\end{remark}

Let us now proceed to define our encoding and decoding more formally. For this, we need bases of the relevant lattices.
% Still, we can define a reference solution $\vec{p}_i' \coloneqq \decompmod{q}(h)$ and consider the difference $\vec{\delta}_i = \vec{p}_i - \vec{p}'_i$.
% The differences are short (because both $\norm{\vec{p}_i}$ and $\norm{\vec{p}'_i}$ are small) and, by construction, satisfy $\projmod{q}(\vec{\delta}_i) = 0$.
% We can then replace transmission of most $\vec{p}_i$'s by transmission of $\vec{\delta}_i$'s.
% So our task boils down to efficiently encode small elements (in $\norm{.}_{\infty}$-norm) from the lattice $\latmodular \coloneqq \{\vec{x}\in\ring^\limbs \mid \projring(\vec{x})\bmod q = 0\}$, where $\limbs = \ceil{\log_{2\eta+1}q}$.

\begin{proposition}\label{prop:kernellattices}
Let $q,\eta$ be positive integers with $q$ prime. Set $\limbs \coloneqq \ceil{ \log_{2\eta+1}q}$ and define lattices
\begin{align*}
\latring    \coloneqq &\{\vec{v}\in\ring^\limbs \mid \projring(\vec{v}) = 0\}\\
\latmodular \coloneqq &\{\vec{v}\in\ring^\limbs \mid \projmod{q}(\vec{v}) = 0\}\\
\end{align*}
for the kernels of $\projring$ and $\projmod{q}$, respectively.
Define vectors $\vec{b}_0,\vec{b}_1,\ldots,\vec{b}_{\limbs-1} \in \ring^\limbs$ as
\begin{align*}
\vec{b}_0 &= (q,0,0,\ldots, 0)\\
\vec{b}_1 &= (-(2\eta+1), 1, 0,0,\ldots, 0)\\
\vec{b}_2 &= (0, -(2\eta+1), 1, 0,\ldots, 0)\\
\ldots\\
\vec{b}_{\limbs-1}&=(0,0,\ldots,0, -(2\eta+1), 1)\enspace.
\end{align*}
Then $\latring$ and $\latmodular$ are $\ring$-module lattices. A basis over $\ring$ for $\latring$ is given by $\kernelbasis \coloneqq \{\vec{b}_1,\ldots,\vec{b}_{\limbs-1}\}$ and
a basis over $\ring$ for $\latmodular$ is given by $\{\vec{b}_0,\ldots,\vec{b}_{\limbs-1}\}$.
\end{proposition}
\begin{proof}
Being kernels of $\ring$-linear maps, $\latring$ and $\latmodular$ are clearly $\ring$-module lattices. Recall that $\projring$ is defined as
\[
\projring\colon\,\ring^\limbs\to\ring, \quad \projring(v_0,v_1,\ldots, v_{\limbs-1}) = \sum_{i=0}^{\limbs-1} (2\eta+1)^i \cdot v_i\enspace.
\]
We thus have $\projring(\vec{b}_0) = q$ and $\projring(\vec{b}_i) = 0$ for $1\leq i \leq \limbs-1$.
Hence, all $\vec{b}_i$ are in the appropriate lattices.
They are also clearly linearly independent.
To show that they also span $\latring$ resp.\ $\latmodular$, consider any $\vec{x}\in\ring^\limbs$.
Without the first column, $\kernelbasis$, viewed as a matrix, is a $(\limbs-1)\times (\limbs-1)$ lower triangular matrix with 1's on the diagonal.
This implies that the projection of $\Span_\ring\kernelbasis$ onto the last $\limbs-1$ coefficients is all of $\ring^{\limbs-1}$, and this projection is bijective.
This means that we can reduce $\vec{x}$ modulo $\Span_\ring \kernelbasis$ to obtain
\[
  \vec{x}\equiv (x',0,0,\ldots, 0) \mod \Span\nolimits_\ring\kernelbasis
\]
for some uniquely determined $x'\in\ring$.
Since $\Span_\ring\kernelbasis\subset \latring$, we have 
\[
 \projring(\vec{x}) = \projring(x',0,\ldots, 0) = x'\enspace. 
\]
Consequently, iff $\vec{x}\in\latring$, we have $\vec{x}\equiv 0 \mod \Span_\ring\kernelbasis$, so $\latring = \Span_\ring\kernelbasis$.
Similarly, iff $\vec{x}\in\latmodular$, we have $\vec{x}\equiv (x',0,\ldots, 0) \mod \Span_\ring\kernelbasis$ with $x'\bmod q = 0$. This shows that $\kernelbasis\cup\{\vec{b}_0\}$ is a basis of $\latmodular$.
\qed
\end{proof}
Following the ideas presented above, the naive approach would correspond to encoding vectors from $\latmodular$ by their coefficients (in $\ring$) wrt.\ $\{\vec{b}_0,\ldots,\vec{b}_{\limbs-1}\}$.
While this would indeed work out, the size of the resulting coefficients depends on how good the chosen basis is.
For the $\norm{.}_\infty$-norm, we would ideally want the basis vectors to be (nearly) orthogonal and parallel to the coordinate axes.
Observe that for large $\eta$, this holds true at least for $\kernelbasis$, but not for $\vec{b}_0$, which is why we treat this coordinate specially\footnote{We could replace $\vec{b}_0$ by a different, more ``reduced'', basis vector here. A canonical choice would be $\decompring(q)$. However, this would not solve the issue.}.

Formally, we define encoding and decoding algorithms $\latencode$ and $\latdecode$ as in \autoref{fig:EncodingCoeff}.

% \gnote{Define lattice(s), $b_i$'s and extra basis vector.}

% \gnote{Note about extra basis vector}

% \gnote{Intro: Define encoding / decoding of points from lattice}

\begin{figure}[ht]
 \begin{pchstack}[center,boxed]
   \procedure{$\latencode(\vec{v}, h)$}{
   \limbs \coloneqq \ceil{\log_{2\eta+1}q}\\
%    \text{Obtain $\eta, q, \limbs$ from $\params$ with $\limbs = \ceil{\log_{2\eta+1}q}$}\\
   \text{Represent $h\in\ring_q$ by $h'\in\ring$, $\norm{h'}\leq \tfrac{q-1}{2}$}\\
   \pcif \projmod{q}(\vec{v}) \neq h\\
   \quad \pcreturn \bot\\
   \delta_q\coloneqq\frac{\projring(\vec{v})-h'}{q}\in\ring\\
   \delta_v\coloneqq \vec{v}- \decompring(\projring(\vec{v}))\in\ring\\
   \text{Find $\alpha_1,\ldots, \alpha_{\limbs-1}\in\ring$ s.t.}\\
   \quad \delta_v = \alpha_1 \vec{b}_1 + \ldots + \alpha_{\limbs-1}\vec{b}_{\limbs-1}\\
   \pcreturn \overline{\vec{v}} = (\delta_q, \alpha_1, \ldots, \alpha_{\limbs-1})
   }
  \pchspace
   \procedure{$\latdecode(\overline{\vec{v}}, h)$}{
   \limbs \coloneqq \ceil{\log_{2\eta+1}q}\\
%    \text{Obtain $\eta, q, \limbs$ from $\params$ with $\limbs = \ceil{\log_{2\eta+1}q}$}\\
   \text{Represent $h\in\ring_q$ by $h'\in\ring$, $\norm{h'}\leq \tfrac{q-1}{2}$}\\
   \pcparse \overline{\vec{v}} \pcas (\delta_q, \alpha_1,\ldots, \alpha_{\limbs-1})\\
   h''\coloneqq h' + q\cdot \delta_q \pccomment{We show $h''=\projring(\vec{v})$}\\
   \delta_v \coloneqq \alpha_1 \vec{b}_1 + \ldots + \alpha_{\limbs-1}\vec{b}_{\limbs-1}\\
   \pcreturn \decompring(h'') + \delta_v \in\ring^\limbs
   }
 \end{pchstack}
 \caption{%
    Algorithms for encoding and decoding and element $\vec{v}\in\ring^\limbs$ when we are given $h = \projmod{q}(\vec{v})$.
%     We assume that the public parameters $\params$ define $q, \eta, \limbs = \ceil{\log_{2\eta+1}q}$.
    The vectors $\vec{b}_1,\ldots, \vec{b}_{\limbs-1}$ are the basis of $\latring$ as defined in \autoref{prop:kernellattices}.
    }
 \label{fig:EncodingCoeff}
\end{figure}

\begin{lemma}[Properties of $\latencode$ and $\latdecode$]\label{lem:latencode}
Let $q,\eta,\limbs$ be positive integers with $q$ prime and $\limbs = \ceil{\log_{2\eta+1}q}$. Let $\params$ be some public parameters determining those integers.
Then the deterministic encoding and decoding algorithms defined in \autoref{fig:EncodingCoeff} satisfy the following properties:
\begin{enumerate}
 \item Coefficients $\alpha_1\ldots,\alpha_{\limbs-1}$ as required in $\latencode$ exist, are unique and can be found in polynomial time.\label{item:basis}
 \item For any $\vec{v}\in\ring^\limbs$ and $h = \projmod{q}(\vec{v})$ and $\overline{\vec{v}} \gets \latencode(\vec{v}, h)$ we have\\
 $\overline{\vec{v}}\neq \bot$ and $\latdecode(\overline{\vec{v}}, h) = \vec{v}$.\label{item:inverse1}
 \item For any $\overline{\vec{v}}\in\ring^\limbs$, and $h\in\ring_q$, $\vec{v}\gets\latdecode(\overline{\vec{v}}, h)$, we have\\
 $\projmod{q}(\vec{v})  = h$ and $\latencode(\vec{v}, h) = \overline{\vec{v}}$.\label{item:inverse2}
 \item For any $\vec{v}\in\ring^\limbs$ and $h \coloneqq \projmod{q}(\vec{v})$, $(\delta_q,\alpha_1,\ldots,\alpha_{\limbs-1}) \gets \latencode(\vec{v},h)$, we have
 \begin{align*}
   \norm{\delta_q} <& \frac{\norm{\projring(\vec{v})}}{q} + \frac{1}{2}\\
   \norm{\alpha_i} <& \frac{\norm{\vec{v}}}{2\eta} + \frac{1}{2} 
 \end{align*}\label{item:latencodebounds}
\end{enumerate}
\end{lemma}
\begin{proof}
For each of the individual claims, let notation be as in the definitions of the algorithms in \autoref{fig:EncodingCoeff}.
Note that variables $\delta_q,\delta_v, h, h', \alpha_1\ldots,\alpha_{\limbs-1}$ appearing in both $\latencode$ and $\latdecode$ with the same name actually have the same value as far as this proof is concerned.
This only matters for \autoref{item:inverse1}, where it is obvious, and for \autoref{item:inverse2}, where we actually need to prove it for $\delta_v, \delta_q,\alpha_1,\ldots,\alpha_{\limbs-1}$.

\medskip\noindent
Let us now prove each individual claim in order.

\bigskip\noindent
For \autoref{item:basis}, note that $\projring(\decompring(\vec{x})) = \vec{x}$ for all $\vec{x}\in\ring$. This implies that
\[
 \projring(\delta_v) = \projring(\vec{v}) - \projring(\decompring(\projring(\vec{v}))) = \projring(\vec{v}) - \projring(\vec{v}) = 0\enspace.
\]
So $\delta_v\in\latring$ and, by \autoref{prop:kernellattices}, coefficients $\alpha_i$ exist and are unique.
They can clearly be found by solving a system of linear equations (over $\ring$).
In fact, $\kernelbasis$ is already in appropriate echelon form, so this can even be done without divisions in $\ring$ and is clearly polynomial time.

\bigskip\noindent
For \autoref{item:inverse1}, we clearly have $\overline{\vec{v}} \neq \bot$.
During decoding, note that
\[
 h'' = h' + q\cdot\delta_q = h'+q\cdot\frac{\projring(\vec{v})-h'}{q} = \projring(\vec{v})\enspace.
\]
It follows that
\[
 \latdecode(\overline{\vec{v}}, h) = \decompring(h'') + \delta_v = \decompring(\projring(\vec{v})) + (v - \decompring(\projring(\vec{v}))) = \vec{v}\enspace,
\]
as desired.


\bigskip\noindent
For \autoref{item:inverse2}, let $\delta_q, \delta_v, \alpha_i$ denote the values used during the computation by $\latdecode$.
While the equally named values in $\latencode$ are actually the same, we need to prove this.
First, note that $\projring(\vec{b}_i) = 0$ for all $1\leq i \leq \limbs-1$.
By $\ring$-linearity, it follows that $\projring(\delta_v) = 0$. From this, we get
\[
 \projring(\vec{v}) = \projring(\decompring(h'') + \delta_v) = h'' = h' + q\cdot \delta_q \equiv h' \equiv h \mod q\enspace,
\]
so $\projmod{q}(\vec{v}) = h$.
During the computation of $\latencode(\vec{v}, h)$ with $\vec{v}$ output by $\latdecode$, note that
\[
 \frac{\projring(\vec{v} - h')}{q} = \frac{\projring(\decompring(h'')+\delta_v)-h'}{q} = \frac{h''-h'}{q} = \delta_q\enspace,
\]
using again linearity and that $\projring(\delta_v) = 0$.
So the value of $\delta_q$ recovered inside $\latencode$ is the same as the value of $\delta_q$ in $\latdecode$.
Similarly, during the computation in $\latencode$, we have
\begin{align*}
 \vec{v}-\decompring(\projring(\vec{v})) 
 ={}& \decompring(h'') + \delta_v - \decompring(\projring(\decompring(h'')+\delta_v))\\
 ={}& \decompring(h'') + \delta_v - \decompring(\projring(\decompring(h''))+\projring(\delta_v))\\
 ={}& \decompring(h'') + \delta_v - \decompring(\projring(\decompring(h''))+ 0)\\
 ={}&\decompring(h'') + \delta_v - \decompring(h'') = \delta_v\enspace,
\end{align*}
so the value for $\delta_v$ obtained in $\latencode$ is the same as that in $\latdecode$.
Since $\kernelbasis$ is an $\ring$-basis, it follows that the values of the $\alpha_i$ are also the same, which proves this item.

\bigskip\noindent
We now tackle the last \autoref{item:latencodebounds}, giving bounds on the encodings.
The first bound is just an easy application of the triangle inequality:
\[
 \norm{\delta_v} = \norm{ \frac{\projring(\vec{v}) - h}{q}} \leq \frac{1}{q} \Bigl( \norm{\projring(\vec{v})} + \norm{h}\Bigr)
 \leq \frac{1}{q}\Bigl(\norm{\projring(\vec{v})} + \frac{q-1}{2}\Bigr)
 < \frac{\norm{\projring(\vec{v})}}{q} + \frac{1}{2}
\]
For the other bound, let us look at the individual components of $\vec{v}$ and $\decompring(\projring(\vec{v})) \in\ring^\limbs$.
For this, set $(w_0,\ldots, w_{\limbs-1})  \coloneqq \decompring(\projring(\vec{v}))$ and 
$(v_0,\ldots,v_{\limbs-1}) \coloneqq \vec{v}$ with $v_i,w_i\in\ring$.
By definition of $\decompring$, we have $\norm{w_i}\leq \eta$ for $0\leq i < \limbs-1$.
Note that this bound excludes the most significant limb.
Writing the equation $\delta_v = \alpha_1\vec{b}_1 + \ldots + \alpha_{\limbs-1}\vec{b}_{\limbs-1}$ in its components, using the definition of $\kernelbasis$ gives the following linear system of equations (over $\ring$) in variables $\alpha_1,\ldots,\alpha_{\limbs-1}$.
\begin{align*}
v_0 - w_0 &= -(2\eta+1)\alpha_1\\
v_1 - w_1 &= \alpha_1 - (2\eta+1)\alpha_2\\
v_2 - w_2 &= \alpha_2 - (2\eta+1)\alpha_3\\
\ldots\\
v_{\limbs-2} - w_{\limbs-2} &= \alpha_{\limbs-2} - (2\eta+1)\alpha_{\limbs-1}\\
v_{\limbs-1} - w_{\limbs-1} &= \alpha_{\limbs-1}
\end{align*}
We now prove the bound for $\norm{\alpha_i}$ by induction over $i$, using those equations\footnote{We have more equations than variables $\alpha_i$ and we will not use the last equation.}.

\smallskip\noindent
For $i=0$, the first equation above gives $\alpha_1 = -\frac{v_0-w_0}{2\eta+1}$. This implies
\[
  \norm{\alpha_1} \leq \frac{\norm{v_0} + \norm{w_0}}{2\eta+1} \leq \frac{\norm{\vec{v}}}{2\eta+1} + \frac{\eta}{2\eta+1} < \frac{\norm{\vec{v}}}{2\eta} + \frac12\enspace.
\]
For $0<i\leq \limbs-1$, we have $\alpha_i = -\frac{v_{i-1}-w_{i-1} - \alpha_{i-1}}{2\eta+1}$. By induction, we can bound this as
\[
 \norm{\alpha_i} 
 \leq \frac{ \norm{v_{i-1}} + \norm{w_{i-1}} + \norm{\alpha_{i-1}} } {2\eta+1}  
 < \frac{ \norm{\vec{v}} + \eta + \frac{\norm{\vec{v}}}{2\eta} + \frac{1}{2} }{2\eta+1} = \frac{\norm{\vec{v}}}{2\eta} + \frac{1}{2}\enspace,
\]
which finishes the proof.\qed
\end{proof}
% We remark that for $\vec{v}\in\ring^\limbs, h=\proj_q(\vec{v})$, with $\norm{\vec{v}}\leq \eta$, $\norm{\proj_q(\vec{v})} < \tfrac{q}{2}$, the bounds from \autoref{lem:latencode} implies
% $\norm{\overline{\vec{v}}} < 1$ for $\overline{\vec{v}}\gets\latencode(\params, \vec{v}, h)$. This corresponds to the situation we have for individually verifying signatures

\begin{definition}\label{def:linearlygoodopenings}
Let $n,\eta, q,q',\xi\in\NN$ with $n$ a power of two, $q,q'$ primes.
Consider the HVC construction $\hvcplain$ from \autoref{fig:hvcinst} with openings from
$\modopening = (\ring^\limbs)^{2\tau} \times (\ring^{\limbs'})^\xi$, where $\limbs = \ceil{\log_{2\eta+1}q}$, $\limbs' = \ceil{\log_{2\eta+1}q'}$.
Let $\params\gets\setup(\secparam)$ be fixed, defining coefficients $\vec{g},\vec{h}_0,\vec{h}_1$ for Ajtai's hash functions.

We call an opening $\vec{d} = (\vec{p}_1,\ldots,\vec{p}_\tau, \vec{s}_1,\ldots,\vec{s}_\tau,\vec{u})$ linearly verifying for time slot $t, 0\leq t<2^\tau$ iff the following conditions hold
\begin{align*}
\vec{g}^\transpose \cdot \vec{u} & =  \projmod{q}(\vec{p}_\tau)\\
\projmod{q}(\vec{p}_{j-1}) & = \vec{h}_{\tilde t_j}^\transpose\cdot \vec{p}_{j} + \vec{h}_{\tilde t_j \xor 1}^\transpose \cdot \vec{s}_{j}\enspace,
\end{align*}
where $\tilde{t} = \binsca(t)$ is the binary decomposition of $t$. We define $\modlinear{t}\subset\modopening$ to be the subset of all linearly verifying openings for $t$.
Since $\modlinear{t}$ is defined via $\ring$-linear constraints, $\modlinear{t}$ is an $\ring$-submodule of $\modopening$.
\end{definition}
By construction, any opening that passes either individual, weak or strong verification must be linearly verifying.
Whether a given opening $\vec{d}$ is linearly verifying or not can be checked in polynomial time, given only $\vec{d}$ and public data $\params$ and $t$.

We now define an efficient encoding scheme for linearly verifying openings in \autoref{fig:EncodingOpenings}.
% \begin{definition}\label{def:latencode}
% Let $n, q, q', \eta, \xi,\tau \in\NN$ with $n$ a power of two, $q,q'$ primes.
% \end{definition}
\begin{figure}[ht]
\begin{pchstack}[center,boxed]
  \procedure{$\openencode(\params, t, \vec{d})$}{
     \tilde t \coloneqq \binsca(t)\\
     \pcparse \vec{d} \pcas (\vec{p}_1,\dots,\vec{p}_\tau,\vec{s}_1,\dots,\vec{s}_\tau,\vec{u})\\
     \pcif \vec{d}\notin \modlinear{t}\\
     \quad\pcreturn \bot\\
     \pcfor j\in\{2,\ldots, \tau\}\\
     \quad \hint_{j-1} \coloneqq \vec{h}_{\tilde t_j}^\transpose\cdot \vec{p}_{j} + \vec{h}_{\tilde t_j \xor 1}^\transpose \cdot \vec{s}_{j} \in\ring_q\\
     \hint_\tau \coloneqq \vec{g}^\transpose\cdot \vec{u} \in\ring_q\\
     \pcfor j\in\{1,\ldots, \tau\}\\
     \quad \overline{\vec{p}}_j \coloneqq \latencode(\vec{p}_j, \hint_j)\\
     \quad \pcif \overline{\vec{p}}_j = \bot\\
     \quad\quad \pcreturn \bot\\
     \overline{\vec{d}}\coloneqq (\overline{\vec{p}}_1,\ldots,\overline{\vec{p}}_\tau, \vec{s}_1,\ldots,\vec{s}_\tau,\vec{u})\\
     \pcreturn \overline{\vec{d}}
   }
  \pchspace
    \procedure{$\opendecode(\params, t, \overline{\vec{d}})$}{
      \tilde t \coloneqq \binsca(t)\\
      \pcparse \overline{\vec{d}} \pcas (\overline{\vec{p}}_1,\dots,\overline{\vec{p}}_\tau,\vec{s}_1,\dots,\vec{s}_\tau,\vec{u})\\
      \hint_\tau \coloneqq \vec{g}^\transpose\cdot \vec{u}  \in\ring_q\\
      \pcfor j\in\{\tau,\ldots, 1\} \pccomment{loop downward}\\
      \quad \vec{p}_j \coloneqq \latdecode(\overline{\vec{p}}_j, \hint_j)\\
      \quad \hint_{j-1} \coloneqq \vec{h}_{\tilde t_j}^\transpose\cdot \vec{p}_{j} + \vec{h}_{\tilde t_j \xor 1}^\transpose \cdot \vec{s}_{j} \in\ring_q\\
      \pccomment{Note: $\hint_0$ is unused}\\
      \vec{d} \coloneqq (\vec{p}_1,\ldots,\vec{p}_\tau,\vec{s}_1,\ldots,\vec{s}_\tau,\vec{u})\\
      \pcreturn \vec{d}
    }
  \end{pchstack}
 \caption{%
    Algorithms for encoding and decoding openings for a given time slot.
%     We assume that the public parameters $\params$ determine $q, \eta, \limbs = \ceil{\log_{2\eta+1}q}$.
%     The vectors $\vec{b}_1,\ldots, \vec{b}_{\limbs-1}$ are the basis of $\latring$ as defined in \autoref{prop:kernellattices}.
    }
 \label{fig:EncodingOpenings}
\end{figure}

% \gnote{Double check that the order of arguments is consistent.}

\begin{theorem}[Efficient encoding of decommitments]\label{thm:EncodingOfOpenings}
Let $n,q,q',\eta,\xi\in\NN$ with $n$ a power of two, $q,q'$ primes.
Let $\params\gets\setup(\secparam)$ be fixed, defining coefficients $\vec{g},\vec{h}_0,\vec{h}_1$ for Ajtai's hash functions.
Fix a time slot $t$ with $0\leq t < 2^\tau$.
Define $\modlinear{t}\subset \modopening$ as in \autoref{def:linearlygoodopenings}, where\footnote{We write the domain of $\openencode$ as $\modopening$ resp.\ $\modlinear{t}$ and the range as $\ring^\oplen$. Even though those are the same as sets, we only view the domain as an $\ring$-module in the usual way.} $\modopening = \ring^\oplen$.
Then $\openencode$ and $\opendecode$, as defined in \autoref{fig:EncodingOpenings} satisfy the following properties.
\begin{enumerate}
 \item $\openencode$ and $\opendecode$ are deterministic polynomial time algorithms. \label{item:openencodeispt}
 \item For any $\vec{d}\in\modopening,\overline{\vec{d}} \coloneqq \openencode(\params,t, \vec{d})$, we have $\overline{\vec{d}} = \bot$ iff $\vec{d}\notin \modlinear{t}$.\label{item:openencodeworks}
 \item For any $\overline{\vec{d}}\in\ring^\oplen, \vec{d}\coloneqq \opendecode(\params,t, \overline{\vec{d}})$, we have $\vec{d}\in\modlinear{t}$. \label{item:opendecodeworks}
 \item For fixed $\params$ and time slot $t$, the functions 
 \begin{align*}
 \openencode(\params, t, .)\colon\,\modlinear{t} \to \ring^\oplen&,\ \vec{d}\mapsto \openencode(\params,t, \vec{d})\\
 \opendecode(\params, t, .)\colon\,\ring^\oplen \to \modlinear{t}&,\ \overline{\vec{d}}\mapsto \opendecode(\params,t, \overline{\vec{d}})
 \end{align*}
are inverses to each other.\label{item:openencodeinverse}
\item Let $\vec{d}\in\modopening$ and $(\overline{\vec{p}}_1,\ldots,\overline{\vec{p}}_\tau,\vec{s}_1,\ldots,\vec{s}_\tau,\vec{u}) \coloneqq \overline{\vec{d}}\coloneqq \openencode(\params,t, \vec{d})$. Let $\vec{c}\in\modcommit$ be any (possibly maliciously generated) commitment and let $\verify$ be as in \autoref{fig:hvcinst}. If $\verify(\params, \vec{c}, t,\vec{d}, \beta) \neq \bot$ for some $\beta$, then \label{item:openencodebounds}
\[
 \norm{\overline{\vec{p}}_i} < \frac{\beta}{2\eta} + \frac12\quad\text{for all $i$}\enspace.
\]
\end{enumerate}
We remark that for individually verifying openings, we have $\beta=\eta$ above, so the bound reads $\norm{\overline{\vec{p}}_i} < 1$ for this case, meaning that $\overline{\vec{p}}_i = 0$.
This just captures the fact that in this case, we can use the usual Merkle tree trick of not transmitting the $\vec{p}_i$, but letting the verifier compute them.
\end{theorem}
\begin{proof}
For \autoref{item:openencodeispt}, there is nothing to show, really.

\bigskip\noindent
For \autoref{item:openencodeworks}, this follows directly from the definitions.
By \autoref{lem:latencode} resp.\ the definition of $\openencode$, we have that $\overline{\vec{p}}_j = \bot$ iff $\projmod{q}(\vec{p}_j) \neq \hint_j$.
Our definition of what it means for an opening to be linearly verifying precisely matches this.

\bigskip\noindent
For \autoref{item:openencodeinverse}, let us first show that $\opendecode(\params, t, \openencode(\params,t, \vec{d})) = \vec{d}$ for all $\vec{d}\in\modlinear{t}$.
For this, observe that (by induction over $j$, starting at $j=\tau$ and going down) both the $\hint_j$ and, by \autoref{item:inverse1} of \autoref{lem:latencode}, the $\vec{p}_j$ constructed during $\opendecode$ are the same as in $\openencode$.

Now consider the other direction, i.e.\ that $\openencode(\params, t,\opendecode(\params,t,\overline{\vec{d}})) = \overline{\vec{d}}$ for all $\overline{\vec{d}}\in\ring^{\oplen}$.
Here, we can see directly from the definition that the values of $\hint_j$ constructed by $\openencode$ are the same as in $\opendecode$.
From \autoref{item:inverse2} of \autoref{lem:latencode}, we then get that all $\overline{\vec{p}}_j$ constructed by $\openencode$ are the same as the input to $\opendecode$, showing that claim.

Observe that we also showed here that $\openencode$ does not output $\bot$, which proves \autoref{item:opendecodeworks} along the way.

\bigskip\noindent
For \autoref{item:openencodebounds}, write $\vec{d} = (\vec{p}_1,\ldots,\vec{p}_\tau,\vec{s}_1,\ldots, \vec{s}_\tau,\vec{u})$.
Recall that $\verify(\params, \vec{c},t,\vec{d},\beta) \neq \bot$ checks among other things that
\[
 \norm{\vec{p}_j} \leq \beta \quad\text{and}\quad \norm{\projring(\vec{p}_j)}\leq \frac{q\beta}{2\eta} \quad\text{for all $1\leq i \leq \tau$}\enspace.
\]
Plugging this into \autoref{item:latencodebounds} of \autoref{lem:latencode} directly gives $\norm{\vec{p}_j} < \frac{\beta}{2\eta}+\frac12$ for all $j$.
\qed
\end{proof}

We can use $\openencode(\params, t, .)$ and $\opendecode(\params, t, .)$ to store and transmit openings:
By \autoref{item:openencodebounds} of \autoref{thm:EncodingOfOpenings}, the encoded openings have smaller norm than the unencoded versions, which can be used to save space.
The restriction that $\openencode(\params, t, .)$ only works for linearly verifying openings is immaterial, as openings violating this condition will never be valid anyway.

\gnote{I wonder to what extent \autoref{thm:encodedhvcworks} and possibly even \autoref{def:encodedhvc} are kind-of obvious and treating this so formally may not be terribly helpful.}
Formally, we can define an encoded version of Chipmunk's HVC as follows:
\begin{definition}\label{def:encodedhvc}
Let $n,q,q',\alpha_w,\rho,\eta,\tau,\xi,\bagg$ be positive integers such that $n$ is a power of two, $q,q'$ are prime.
Let $\hvcplain = (\setup,\commit,\open,\iverify,\sverify, \wverify)$ be the HVC from \autoref{fig:hvcinst} for its domain $\moddomain$ and vectors of length $2^\tau$.
Denote by $\modopening$ and $\modcommit$ the $\ring$-modules where the openings and commitments are from.
Recall that $\modopening$ has the form $\modopening = \ring^\oplen$.

We can then define and encoded version $\hvcencoded = (\setup',\commit',\open',\iverify',\sverify', \wverify')$ by simply encoding/decoding the openings as follows:
\begin{description}
    \item[$\setup'(\secparam)$:] Identical to $\setup$.
    \item[$\commit'(\params, \vec{m})$:] Identical to $\commit$.
    \item[$\open'(\params,\vec{c},\vec{m},t)$:] Run $\vec{d}\gets\open(\params,\vec{c},\vec{m},t)$ and output $\overline{\vec{d}} = \openencode(\params, t, \vec{d})$.
    \item[$\iverify'(\params, \vec{c},t,\overline{\vec{d}})$:] Run $\vec{d}\gets\opendecode(\params,t,\overline{\vec{d}})$. Output whatever $\iverify(\params,\vec{c},t,\vec{d})$ outputs.
    \item[$\sverify'(\params, \vec{c},t,\overline{\vec{d}})$:] Run $\vec{d}\gets\opendecode(\params,t,\overline{\vec{d}})$. Output whatever $\sverify(\params,\vec{c},t,\vec{d})$ outputs.
    \item[$\wverify'(\params, \vec{c},t,\overline{\vec{d}})$:] Run $\vec{d}\gets\opendecode(\params,t,\overline{\vec{d}})$. Output whatever $\wverify(\params,\vec{c},t,\vec{d})$ outputs.
\end{description}
\end{definition}
Note that the opening space of $\hvcencoded$ is $\ring^\oplen$.
However, to perform homomorphic operations on openings, we need to operate on the \emph{unencoded} values, since encoding/decoding is not a $\ring$-linear operation with the usual $\ring$-module structure on $\ring^\oplen$.
To formally satisfy the homomorphism requirements, we therefore need to endow the set $\ring^\oplen$ with a (non-standard) $\ring$-module structure $\modencoded{t} = (\ring^\oplen, \odot, \oplus)$, where scalar multiplication $\odot$ by ring elements and the addition $\oplus$ are given by
\begin{align*}
 \odot\colon\,\ring\times\modencoded{t}\to\modencoded{t},&\quad w\odot \overline{\vec{d}} \coloneqq \openencode(\params,t, w\cdot\opendecode(\params, t, \overline{\vec{d}}))\\
 \oplus\colon\,\modencoded{t}\times\modencoded{t},&\quad \overline{\vec{d}}_1 \oplus \overline{\vec{d}}_2 \coloneqq \openencode(\params, t, \opendecode(\params,t,\overline{\vec{d}}_1) + \opendecode(\params, t,\overline{\vec{d}}_2))
\end{align*}
This gives an $\ring$-module $\modencoded{t}$, which is the opening space of $\hvcencoded$.
Note that it depends on $t$.

\begin{theorem}\label{thm:encodedhvcworks}
Let $n, q, q',\alpha_w,\rho, \eta, \tau, \xi, \bagg$ be positive integers and $0<\errorbound \leq 1$ such that $n$ is a power of two and $q,q'$ prime.
Let $\hvcplain = (\setup,\commit,\open,\iverify,\sverify, \wverify)$ be the homomorphic vector commitment from \autoref{fig:hvcinst} and $\hvcencoded = (\setup,\commit,\open',\iverify',\sverify', \wverify')$ be the encoded version from \autoref{def:encodedhvc} based on it for those parameters.
Then $\hvcencoded$ is individually correct, $(\rho,\tern_{\alpha_w},\errorbound)$-probabilistically homomorphic, robustly homomorphic and position binding for domain $\ring_{q'}^\xi$ and vector length $2^\tau$, provided $\hvcplain$ has those properties.
\end{theorem}
\begin{proof}
There is really not much to show here.

Individual correctness follows directly from \autoref{item:openencodeinverse} of \autoref{thm:EncodingOfOpenings}.

The robust homomorphism properties also follows from this, together with the way we defined $\modencoded{t}$.
Notably, assume we have $\params\gets\setup(\secparam)$, $0\leq t < 2^\tau$, commitments $\vec{c}^0,\vec{c}^1\in\moddomain$ and $\overline{\vec{d}}^0,\overline{\vec{d}}^1\in\modencoded{t}$ with
\[
 \sverify'(\params,\vec{c}^0,t,\overline{\vec{d}}^0) = \vec{m}^0
 \quad\text{and}\quad
 \sverify'(\params,\vec{c}^1,t,\overline{\vec{d}}^1) = \vec{m}^1
\]
such that $\vec{m}^0,\vec{m}^1\neq \bot$.
We need to show that
\[
 \wverify'(\params, \vec{c}^0-\vec{c}^1, t, \overline{\vec{d}}^0 \ominus \overline{\vec{d}}^1) = \vec{m}^0 - \vec{m}^1\enspace,
\]
where $\ominus$ is the subtraction in $\modencoded{t}$ corresponding to $\oplus$.

Let $\vec{d}^0 \coloneqq \opendecode(\params, t, \overline{\vec{d}}^0), \vec{d}^1\coloneqq \opendecode(\params, t, \overline{\vec{d}}^1)$. By definition of $\sverify'$, we have
\[
 \vec{m}^0 = \sverify(\params,\vec{c}^0,t,\vec{d}^0)
 \quad\text{and}\quad
 \vec{m}^1 = \sverify(\params,\vec{c}^1,t,\vec{d}^1)\enspace.
\]
Since $\hvc$ is robustly homomorphic, this yields
\[
 \wverify(\params, \vec{c}^0-\vec{c}^1, t, \vec{d}^0 - \vec{d}^1) = \vec{m}^0 - \vec{m}^1\enspace.
\]
By definition, $\opendecode(\params, t, \overline{\vec{d}}^0 \ominus \overline{\vec{d}}^1) = \vec{d}^0 - \vec{d}^1$. Putting these together, we obtain
\begin{align*}
   &\wverify'(\params, \vec{c}^0-\vec{c}^1, t, \overline{\vec{d}}^0 \ominus \overline{\vec{d}}^1) \\
 = &\wverify (\params, \vec{c}^0 - \vec{c}^1, t, \opendecode(\params, t, \overline{\vec{d}}^0 \ominus \overline{\vec{d}}^1) )\\
 = &\wverify (\params, \vec{c}^0 - \vec{c}^1, t, \vec{d}^0 - \vec{d}^1)\\
 = &\vec{m}^0 - \vec{m}^1\enspace.
\end{align*}

For the probabilistic homomorphism property, let $\params\gets\setup(\secparam), \ell < \rho$ and $0\leq t < 2^\tau$.

For $1\leq i \leq \ell$, consider commitments $\vec{c}^i\in\modcommit$, decommitments $\overline{\vec{d}}^i\in\modencoded{t}$ with $\iverify'(\params, \vec{c}^i,t,\overline{\vec{d}}^i) = \vec{m}^i$ such that $\vec{m}^i\neq \bot$.
We need to show that 
\[
    \Pr\mleft[
      w^1,\dots,w^{\ell} \gets W\colon\;
      \sverify'\Bigl(\params,\sum_{i=1}^{\ell}w^i\cdot \vec{c}^i,t,\bigoplus_{i=1}^{\ell}w^i\odot\overline{\vec{d}}^i\Bigr)
      = \sum_{i=1}^{\ell}w^i\cdot\vec{m}^i_{t}
    \mright] \geq 1-\errorbound \enspace.
\]
For this, set $\vec{d}^i\coloneqq \opendecode(\params, t, \overline{\vec{d}}^i)$. By definition of $\iverify'$, we have $\iverify(\params, \vec{c}^i, t, \vec{d}^i) = \vec{m}^i$. Then we get
\begin{align*}
  &\sverify'\Bigl(\params,\sum_{i=1}^{\ell}w^i\cdot \vec{c}^i,t,                             \bigoplus_{i=1}^{\ell}w^i\odot\overline{\vec{d}}^i        \Bigr)\\
 =&\sverify \Bigl(\params,\sum_{i=1}^{\ell}w^i\cdot \vec{c}^i,t,\opendecode\Bigl(\params, t, \bigoplus_{i=1}^{\ell}w^i\odot\overline{\vec{d}}^i \Bigr) \Bigr)\\
 =&\sverify \Bigl(\params,\sum_{i=1}^{\ell}w^i\cdot \vec{c}^i,t,                                  \sum_{i=1}^{\ell}w^i\cdot          \vec{d}^i         \Bigr)\\
\end{align*}
The claim then follows from the probabilistic homomorphism property of $\hvc$.

Let us look at the position-binding property. For any adversary $\adv$ against the position-binding property of $\hvcencoded$, we construct an adversary $\bdv$ against $\hvc$ as follows.

$\bdv(\params)$ runs $(\vec{c}, t, \overline{\vec{d}}_0,\overline{\vec{d}}_1)\gets\adv(\params)$ and outputs $(\vec{c}, t, \opendecode(\params, t,\overline{\vec{d}}_0), \opendecode(\params, t, \overline{\vec{d}}_1))$. It is easy to see that $\adv$ is successful iff $\bdv$ is.\qed
%Note here that $\openencode(\params, t, \overline{\vec{d}}_0)$ or $\openencode(\params, t, \overline{\vec{d}}_1)$ may be $\bot$. This is fine: in that case, 
\end{proof}

\begin{remark}
Let $n, q, q',\alpha_w,\rho, \eta, \tau, \xi, \bagg$ be positive integers such that $n$ is a power of two and $q,q'$ prime.
Let us collect in \autoref{table:hvcsizes} the individual components of our HVC constructions and look at the bit-sizes of commitments and (individually or strongly verifying) openings as functions of the parameters.
Note that the strongly verifying case will correspond to the constribution for the size of aggregated signatures later in \autoref{sec:nidv}, and this size is the most important metric we want to minimize.

A commitment is a (non-short) single element from $\ring_q$. This means we can use $n\ceil{\log q}$ bits to store it.\footnote{In principle, we could do $\ceil{n\log q}$ by using some clever arithmetic encoding; hoever, for simplicity, we assume here that every coefficient is stored individually.}
In the variant without our elaborate encodings, an opening consists of $\oplen = 2\tau\ceil{\log_{2\eta+1}q} + \xi\ceil{\log_{2\eta+1}q'}$ many elements from $\ring$.
Each element is $\norm{.}_\infty$-bounded: for individually verifying openings, the bound is $\eta$, giving $n\oplen\ceil{\log (2\eta+1)}$ bits. For strongly verifying opening, the bound is $\bagg$, giving $n\oplen\ceil{\log (2\bagg+1)}$ bits.

For $\hvcencoded$, an opening consists of the same number of elements from $\ring$, but we have tighter size constraints for $\tau\ceil{\log_{2\eta+1}q}$ of them. For the individually verifying case, those elements are actually 0. In the strongly verifying case, the (non-attained) bound is $\tfrac{\bagg}{2\eta}+\frac12$, giving $n\tau\ceil{\log_{2\eta+1}q}\ceil{\log(2\lfloor\frac{\bagg}{2\eta}+\frac12\rfloor +1 )} \leq n\tau\ceil{\log_{2\eta+1}q}\ceil{\log (\lfloor\tfrac{\bagg}{\eta}\rfloor+2)}$ many bits for the $\overline{\vec{p}}_i$'s.

\begin{table}\centering
 \begin{tabular}{ccc@{\hskip 3.5ex}l}
  & & & size in bits \\\toprule
  commitments & & & $n\ceil{\log q}$\\
  \hline
  \multirow{4}{*}{opening}& \multirow{2}{*}{$\hvcplain$} &individually verifying & $\bigl(2\tau\limbs + \xi\limbs'\bigr)n\cdot \ceil{\log(2\eta+1)}$\\\cline{3-4}
                          &                                   &strongly verifying & $\bigl(2\tau\limbs + \xi\limbs'\bigr)n\cdot \ceil{\log(2\bagg+1)}$  \\\cline{2-4}
                          & \multirow{2}{*}{$\hvcencoded$}    &individually verifying & $\bigl(\tau\limbs + \xi\limbs'\bigr)n\cdot \ceil{\log(2\eta+1)}$\\\cline{3-4}
                          &                                   &strongly verifying & $\bigl(\tau\limbs + \xi\limbs'\bigr)n\cdot \ceil{\log(2\eta+1)}+ \tau\limbs n\normalceil{\log (\lfloor\frac{\bagg}{\eta}\rfloor+2)}$\\
                          \hline
 \end{tabular}
 \medskip % Alternatively, put caption on top (some style guides suggest this)
 \caption{bitlength of our HVC constructions. We denote by $\limbs = \ceil{\log_{2\eta+1}q}$ and $\limbs' = \ceil{\log_{2\eta+1}q'}$ the number of limbs for the decompositions of $\ring_q$ resp.\ $\ring_{q'}$ elements.}
 \label{table:hvcsizes}
\end{table}
\end{remark}
